{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lorapy symbol extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import os, sys\n",
    "from loguru import logger\n",
    "logger.remove(None)\n",
    "logger.add(sys.stdout, colorize=True, enqueue=True)\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorapy\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.signal as spsig\n",
    "import warnings\n",
    "import multiprocessing\n",
    "from functools import partial \n",
    "import time\n",
    "\n",
    "from lorapy.symbols import utils as sym_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BASE_DATA_DIR = pathlib.Path('../data')\n",
    "\n",
    "DOTP_20K_DATA_DIR = _BASE_DATA_DIR.joinpath('symbol-ref/20k')\n",
    "DOTP_1M_DATA_DIR = _BASE_DATA_DIR.joinpath('symbol-ref/1M')\n",
    "OTA_1M_DATA_DIR = _BASE_DATA_DIR.joinpath('ota-data-1M')\n",
    "OUTDOOR_DATA_DIR = _BASE_DATA_DIR.joinpath('outdoor-to-process')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-04-17 18:35:41.582\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.io._base_loader\u001b[0m:\u001b[36m_validate_data_path\u001b[0m:\u001b[36m140\u001b[0m - \u001b[34m\u001b[1mset datafile directory: ../data/outdoor-to-process\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.io._base_loader\u001b[0m:\u001b[36m_process_data_dir\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mfound 11 data file(s)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DatFile(id=0 | name='lora_BW9_SF12_915MHz_1Msps_L46.dat'),\n",
       " DatFile(id=1 | name='lora_BW7_SF12_915MHz_1Msps_L3.dat'),\n",
       " DatFile(id=2 | name='lora_BW7_SF11_915MHz_1Msps_L4.dat'),\n",
       " DatFile(id=3 | name='lora_BW8_SF11_915_25MHz_1Msps_L37.dat'),\n",
       " DatFile(id=4 | name='lora_BW2_SF11_914_75MHz_1Msps_L19.dat'),\n",
       " DatFile(id=5 | name='lora_BW2_SF11_915MHz_1Msps_L6.dat'),\n",
       " DatFile(id=6 | name='lora_BW7_SF10_915_25MHz_1Msps_L33.dat'),\n",
       " DatFile(id=7 | name='lora_BW2_SF10_915_25MHz_1Msps_L30.dat'),\n",
       " DatFile(id=8 | name='lora_BW7_SF11_914_75MHz_1Msps_L18.dat'),\n",
       " DatFile(id=9 | name='lora_BW9_SF12_915MHz_1Msps_L2.dat'),\n",
       " DatFile(id=10 | name='lora_BW9_SF10_915MHz_1Msps_L1.dat')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = lorapy.load_dat(OUTDOOR_DATA_DIR, autoload=True)\n",
    "loader.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dotp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-04-17 18:35:41.605\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.io._base_loader\u001b[0m:\u001b[36m_validate_data_path\u001b[0m:\u001b[36m140\u001b[0m - \u001b[34m\u001b[1mset datafile directory: ../data/symbol-ref/1M\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.io._base_loader\u001b[0m:\u001b[36m_process_data_dir\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mfound 17 data file(s)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DotPFile(id=0 | name='lora_symbols_BW1_SF7.p'),\n",
       " DotPFile(id=1 | name='lora_symbols_BW2_SF10.p'),\n",
       " DotPFile(id=2 | name='lora_symbols_BW8_SF11.p'),\n",
       " DotPFile(id=3 | name='lora_symbols_BW8_SF9.p'),\n",
       " DotPFile(id=4 | name='lora_symbols_BW1_SF10.p'),\n",
       " DotPFile(id=5 | name='lora_symbols_BW1_SF8.p'),\n",
       " DotPFile(id=6 | name='lora_symbols_BW1_SF11.p'),\n",
       " DotPFile(id=7 | name='lora_symbols_BW8_SF8.p'),\n",
       " DotPFile(id=8 | name='lora_symbols_BW9_SF12.p'),\n",
       " DotPFile(id=9 | name='lora_symbols_BW2_SF11.p'),\n",
       " DotPFile(id=10 | name='lora_symbols_BW8_SF7.p'),\n",
       " DotPFile(id=11 | name='lora_symbols_BW2_SF7.p'),\n",
       " DotPFile(id=12 | name='lora_symbols_BW7_SF12.p'),\n",
       " DotPFile(id=13 | name='lora_symbols_BW2_SF12.p'),\n",
       " DotPFile(id=14 | name='lora_symbols_BW9_SF10.p'),\n",
       " DotPFile(id=15 | name='lora_symbols_BW1_SF12.p'),\n",
       " DotPFile(id=16 | name='lora_symbols_BW1_SF9.p')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ploader = lorapy.load_dotp(DOTP_1M_DATA_DIR)\n",
    "ploader.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## symbol correlation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_step_dict = {\n",
    "    1: 100,\n",
    "    2: 100,\n",
    "    7: 4,\n",
    "    8: 2,\n",
    "    9: 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_matching_dotp(bw: int, sf: int):\n",
    "    return ploader.filter(bw=bw, sf=sf)[0]\n",
    "\n",
    "def _convert_files(file, dotp_file):\n",
    "    return file.to_signal(), dotp_file.to_signal()\n",
    "\n",
    "\n",
    "def _load_and_convert(file):\n",
    "    file.load()\n",
    "    dotp_file = _load_matching_dotp(file.bw, file.sf)\n",
    "    \n",
    "    signal, base_symbol = _convert_files(file, dotp_file)\n",
    "    \n",
    "    return signal, base_symbol\n",
    "\n",
    "\n",
    "def _extract_and_manual_adjust(signal):\n",
    "    signal.extract_packets(method='slide-mean', auto_adj=False, overlap=0.5)\n",
    "    signal.adjust_packets(\n",
    "        force_check=True, \n",
    "        adjust_type='biased-mean', \n",
    "        look_ahead=100, threshold=0.5,\n",
    "    )\n",
    "    \n",
    "    return signal\n",
    "\n",
    "\n",
    "def _format_output_path(base_dir, signal):\n",
    "    filename = pathlib.Path(signal.stats.filename)\n",
    "    \n",
    "    out_path = base_dir.joinpath(\n",
    "        'processed-symbols/outdoor'\n",
    "    ).joinpath(\n",
    "        filename.with_suffix('').with_suffix('.p')\n",
    "    )\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "\n",
    "def _save_symbols(data, signal, base_dir):\n",
    "    out_path = _format_output_path(base_dir, signal)\n",
    "    \n",
    "    with out_path.open('wb') as outfile:\n",
    "        cPickle.dump(data, outfile)\n",
    "\n",
    "        \n",
    "def _extract_symbols(packet):\n",
    "    packet.extract_preamble_window()\n",
    "    return packet._preamble_window\n",
    "\n",
    "\n",
    "def _extract_and_save_symbols(packets):\n",
    "    full_array = np.vstack([\n",
    "        _extract_symbols(packet)\n",
    "        for packet in packets\n",
    "    ])\n",
    "    \n",
    "    packet = packets[0]\n",
    "    _save_symbols(full_array, packet)\n",
    "        \n",
    "\n",
    "def _get_correlation_values(base_symbol, preamble, samp_per_sym, shift_step):\n",
    "    shifts = sym_utils.generate_shifts(\n",
    "        samp_per_sym, range_factor=10, step=shift_step,\n",
    "    )\n",
    "    \n",
    "    corr_vals = sym_utils.shift_and_correlate(\n",
    "        base_symbol.data, preamble, samp_per_sym, shifts,\n",
    "    ) \n",
    "    \n",
    "    return corr_vals\n",
    "\n",
    "def _get_adjusted_distance(samp_per_sym, shift_step):\n",
    "    distance = int(samp_per_sym // shift_step)\n",
    "    distance *= 0.90 \n",
    "    return distance\n",
    "\n",
    "\n",
    "def _find_peaks(corr_vals, samp_per_sym, shift_step):\n",
    "    adjusted_dist = _get_adjusted_distance(samp_per_sym, shift_step)\n",
    "    \n",
    "    peaks = spsig.find_peaks(\n",
    "        corr_vals, \n",
    "        distance=adjusted_dist,\n",
    "    )[0]\n",
    "    \n",
    "    return peaks \n",
    "\n",
    "\n",
    "def _corr_sanity_plot(corr_vals, peaks):\n",
    "    symbol_strips = [\n",
    "        np.max(corr_vals) * 1.1 if idx in peaks else 0\n",
    "        for idx, _ in enumerate([0] * len(corr_vals))\n",
    "    ]\n",
    "    \n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].plot(corr_vals)\n",
    "    axs[1].plot(corr_vals)\n",
    "    axs[1].plot(symbol_strips)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def _extract_symbols_from_peaks(packet_data: np.ndarray, peak_shifts: list, samp_per_sym: int) -> np.ndarray:\n",
    "    symbols = np.vstack([\n",
    "        packet_data[shift: shift+samp_per_sym]\n",
    "        for shift in peak_shifts\n",
    "    ])\n",
    "    \n",
    "    return symbols\n",
    "        \n",
    "\n",
    "def _sanity_plot(symbols):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, ax = plt.subplots(symbols.shape[0])\n",
    "\n",
    "        for idx, sym in enumerate(symbols):\n",
    "            ax[idx].plot(sym)\n",
    "\n",
    "\n",
    "def correlate_and_slice(packet, base_symbol, save_sanity=False):\n",
    "    samp_per_sym, shift_step = packet.stats.samp_per_sym, _step_dict[packet.stats.bw]\n",
    "    \n",
    "    shifts = sym_utils.generate_shifts(\n",
    "        samp_per_sym, range_factor=10, step=shift_step,\n",
    "    )\n",
    "\n",
    "    corr_vals = sym_utils.shift_and_correlate(\n",
    "        base_symbol, packet.data, samp_per_sym, shifts,\n",
    "    ) \n",
    "    \n",
    "    peaks = _find_peaks(corr_vals, samp_per_sym, shift_step)\n",
    "    \n",
    "    shifts = list(shifts)\n",
    "    peak_shifts = [shifts[peak] for peak in peaks]\n",
    "    \n",
    "    symbols = _extract_symbols_from_peaks(packet.data, peak_shifts, samp_per_sym)\n",
    "    \n",
    "    if save_sanity:\n",
    "        _sanity_plot(symbols)\n",
    "    \n",
    "    return symbols\n",
    "\n",
    "\n",
    "\n",
    "def slice_all_packets(packets, symbol_data):\n",
    "    six_symbol_data = np.concatenate([symbol_data] * 6)\n",
    "    corr_slice = partial(correlate_and_slice, base_symbol=six_symbol_data)\n",
    "    \n",
    "    with multiprocessing.Pool() as pool:\n",
    "        results = pool.map(corr_slice, packets)\n",
    "        \n",
    "    min_size = (len(res) for res in results)\n",
    "    results = [res[:min_size] for res in results]\n",
    "    return np.vstack(results)\n",
    "\n",
    "def process_and_save(file):\n",
    "    signal, base_symbol = _load_and_convert(file)\n",
    "    signal = _extract_and_manual_adjust(signal)\n",
    "    results = slice_all_packets(signal.packets, base_symbol.data[0])\n",
    "    \n",
    "    _save_symbols(results, signal, _BASE_DATA_DIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manual process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DatFile(id=0 | name='lora_BW9_SF12_915MHz_1Msps_L46.dat'),\n",
       " DatFile(id=1 | name='lora_BW7_SF12_915MHz_1Msps_L3.dat'),\n",
       " DatFile(id=2 | name='lora_BW7_SF11_915MHz_1Msps_L4.dat'),\n",
       " DatFile(id=3 | name='lora_BW8_SF11_915_25MHz_1Msps_L37.dat'),\n",
       " DatFile(id=4 | name='lora_BW2_SF11_914_75MHz_1Msps_L19.dat'),\n",
       " DatFile(id=5 | name='lora_BW2_SF11_915MHz_1Msps_L6.dat'),\n",
       " DatFile(id=6 | name='lora_BW7_SF10_915_25MHz_1Msps_L33.dat'),\n",
       " DatFile(id=7 | name='lora_BW2_SF10_915_25MHz_1Msps_L30.dat'),\n",
       " DatFile(id=8 | name='lora_BW7_SF11_914_75MHz_1Msps_L18.dat'),\n",
       " DatFile(id=9 | name='lora_BW9_SF12_915MHz_1Msps_L2.dat'),\n",
       " DatFile(id=10 | name='lora_BW9_SF10_915MHz_1Msps_L1.dat')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(loader.file_list, key=lambda fl: fl.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file0 = loader.select(9)\n",
    "file1 = loader.select(1)\n",
    "file2 = loader.select(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-04-17 18:35:41.725\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[33m\u001b[1mworking file: DatFile(id=9 | name='lora_BW9_SF12_915MHz_1Msps_L2.dat')\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.726\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlorapy.utils.filename\u001b[0m:\u001b[36mextract_value\u001b[0m:\u001b[36m20\u001b[0m - \u001b[33m\u001b[1mno matches found [Att(\\d{1,})] in filename lora_BW9_SF12_915MHz_1Msps_L2.dat | None\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.datafile.encoding\u001b[0m:\u001b[36mcompute_params\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1mcomputed samples per symbol: 8192 and packet length: 247808\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.datafile._base_file\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mloaded 15561810 samples from file\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.833\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlorapy.utils.filename\u001b[0m:\u001b[36mextract_value\u001b[0m:\u001b[36m20\u001b[0m - \u001b[33m\u001b[1mno matches found [Att(\\d{1,})] in filename lora_symbols_BW9_SF12.p | None\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:41.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.datafile.encoding\u001b[0m:\u001b[36mcompute_params\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1mcomputed samples per symbol: 8192 and packet length: 247808\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.datafile._base_file\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mloaded 10354688 samples from file\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.signals.signal\u001b[0m:\u001b[36m_process_signal\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mselected \"slide-mean\" processing method\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.signals.processing.sliding_mean\u001b[0m:\u001b[36m_find_all_mindices\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mscanning signal for padding locations..\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.314\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.processing.sliding_mean\u001b[0m:\u001b[36m_find_all_mindices\u001b[0m:\u001b[36m59\u001b[0m - \u001b[34m\u001b[1miteration 0\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.361\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.processing.sliding_mean\u001b[0m:\u001b[36m_scan_slice\u001b[0m:\u001b[36m92\u001b[0m - \u001b[34m\u001b[1mreached end of signal\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.processing.utils\u001b[0m:\u001b[36mclean_index_list\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mfound 1 false indexes\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.signals.processing.sliding_mean\u001b[0m:\u001b[36m_find_all_mindices\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mfound [62 // 61] packet locations\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.365\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.packets.utils\u001b[0m:\u001b[36mslice_all_packets\u001b[0m:\u001b[36m21\u001b[0m - \u001b[34m\u001b[1mgot max packet length: 247808\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.packets.utils\u001b[0m:\u001b[36mslice_all_packets\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mextracted 61 packets from signal\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.416\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.signal\u001b[0m:\u001b[36m_slice_and_load\u001b[0m:\u001b[36m65\u001b[0m - \u001b[34m\u001b[1mloaded 61 lora packets\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlorapy.signals.signal\u001b[0m:\u001b[36madjust_packets\u001b[0m:\u001b[36m78\u001b[0m - \u001b[33m\u001b[1mmultiprocessing packet adjustment..\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.675\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.signal\u001b[0m:\u001b[36m_adjust_endpoints\u001b[0m:\u001b[36m96\u001b[0m - \u001b[34m\u001b[1madjusted endpoints\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.packets.utils\u001b[0m:\u001b[36mslice_all_packets\u001b[0m:\u001b[36m21\u001b[0m - \u001b[34m\u001b[1mgot max packet length: 247808\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlorapy.packets.utils\u001b[0m:\u001b[36mslice_all_packets\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mextracted 61 packets from signal\u001b[0m\n",
      "\u001b[32m2020-04-17 18:35:42.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlorapy.signals.signal\u001b[0m:\u001b[36m_slice_and_load\u001b[0m:\u001b[36m65\u001b[0m - \u001b[34m\u001b[1mloaded 61 lora packets\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "os.environ['MULTIPROC'] = 'true'\n",
    "\n",
    "logger.warning(f'working file: {file0}')\n",
    "process_and_save(file0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptioned_files = []\n",
    "os.environ['MULTIPROC'] = 'true'\n",
    "\n",
    "for file in sorted(loader.file_list, key=lambda fl: fl.name):\n",
    "    logger.warning(f'working file: {file}')\n",
    "    process_and_save(file)\n",
    "    \n",
    "#     try:\n",
    "#         process_and_save(file)\n",
    "#     except Exception as exc:\n",
    "#         logger.error(f'encountered exception for file {file}\\n{exc}')\n",
    "#         exceptioned_files.append(file.name) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sleep version"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "exceptioned_files = []\n",
    "done_files = []\n",
    "os.environ['MULTIPROC'] = 'true'\n",
    "\n",
    "while True:\n",
    "    for file in (file for file in loader.file_list if file.name not in done_files):\n",
    "#     for file in loader.file_list:\n",
    "        logger.warning(f'working file: {file}')\n",
    "        try:\n",
    "            process_and_save(file)\n",
    "        except Exception:\n",
    "            exceptioned_files.append(file.name) \n",
    "        else:\n",
    "            done_files.append(file.name)\n",
    "    \n",
    "    \n",
    "    [ time.sleep(1) for _ in range(60 * 15) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptioned_files = []\n",
    "\n",
    "for file in tqdm_notebook(loader.file_list):\n",
    "    file.load()\n",
    "    dotp_file = _load_matching_dotp(file.bw, file.sf)\n",
    "\n",
    "    signal, base_symbol = _convert_files(file, dotp_file)\n",
    "    logger.info(f'\\n{signal}')\n",
    "    logger.info(f'\\n{base_symbol}')\n",
    "    \n",
    "    try:\n",
    "        packets = _extract_and_manual_adjust(base_symbol, _step_dict)\n",
    "        _extract_and_save_symbols(packets)\n",
    "    except Exception:\n",
    "        exceptioned_files.append(file.name) \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filenames = [\n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att0_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att100_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att120_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att140_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att20_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att40_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att60_v1.dat', \n",
    "    'lora_BW1_SF10_915MHz_20ksps_Att80_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20kspsAtt120_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20kspsAtt140_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att0_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att100_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att20_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att40_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att60_v1.dat', \n",
    "    'lora_BW1_SF11_915MHz_20ksps_Att80_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt0_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt0_v2.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt100_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt120_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt140_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt20_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt40_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt60_v1.dat', \n",
    "    'lora_BW1_SF12_915MHz_20kspsAtt80_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att0_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att100_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att120_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att140_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att20_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att40_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att60_v1.dat', \n",
    "    'lora_BW2_SF10_915MHz_20ksps_Att80_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att0_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att100_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att120_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att140_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att20_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att40_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att60_v1.dat', \n",
    "    'lora_BW2_SF11_915MHz_20ksps_Att80_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att0_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att100_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att120_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att140_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att20_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att40_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att60_v1.dat', \n",
    "    'lora_BW2_SF12_915MHz_20ksps_Att80_v1.dat', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
